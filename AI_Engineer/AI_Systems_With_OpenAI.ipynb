{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c825eaf",
   "metadata": {},
   "source": [
    "# Structuring End-to-End Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7e468",
   "metadata": {},
   "source": [
    "## Structuring an API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"XXX\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14ff4a",
   "metadata": {},
   "source": [
    "### Integrating with Production\n",
    "\n",
    "- Error handling\n",
    "\n",
    "- Moderation and safety \n",
    "- Testing and Validation\n",
    "- Communication with External Tools (i.e. agentic systems and MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb872f",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d10d1",
   "metadata": {},
   "source": [
    "- Prevents `RateLimitError` by rocessing multiple messages in one request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\"Canada\", \"France\", \"Germany\", \"Italy\", \"Japan\", \"United Kingdom\", \"United States\"]\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "     You are a helpful assistant that translates English to French.\n",
    "     Provide each of the questions with an answer in the response as separate content.\n",
    "     \"\"\"}\n",
    "]\n",
    "\n",
    "[message.append({\"role\": \"user\", \"content\": f\"Translate the following country name to French: {country}\"}) for country in countries]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=message,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be24ff6",
   "metadata": {},
   "source": [
    "### Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af40ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tenacity library\n",
    "from tenacity import(\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,      \n",
    ")\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Add the appropriate parameters to the decorator\n",
    "@retry(wait= wait_random_exponential(multiplier=1, min=5, max=40), stop = stop_after_attempt(4))\n",
    "def get_response(model, message):\n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[message]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "print(get_response(\"gpt-4o-mini\", {\"role\": \"user\", \"content\": \"List ten holiday destinations.\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e66077",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
