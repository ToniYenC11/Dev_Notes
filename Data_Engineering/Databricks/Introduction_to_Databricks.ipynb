{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e12b0c7",
   "metadata": {},
   "source": [
    "# Introduction to Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f7586b",
   "metadata": {},
   "source": [
    "## Databricks Administration\n",
    "\n",
    "[Administration in Databricks](https://learn.microsoft.com/en-us/azure/databricks/admin/)\n",
    "\n",
    "### Databricks Admin Types\n",
    "\n",
    "- **Account admins** - Manage Azure Databricks account, including enabling Unity Catalog, user provisioning, and account-level identity management.\n",
    "\n",
    "- **Workspace admins** - Manage workspace identities, access control, settings, and features for individual workspaces in the account.\n",
    "\n",
    "- **Metastore admins** - Manage privileges and ownership for all securable objects within a Unity Catalog metastore, such as who can create catalogs or query a table.\n",
    "\n",
    "- **Billing admins** - View budgets and manage the serverless budget policies across account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ea3de",
   "metadata": {},
   "source": [
    "## Databricks Architecture\n",
    "\n",
    "Documentation [here](https://docs.databricks.com/aws/en/getting-started/overview)\n",
    "\n",
    "- **Control Plane** \n",
    "    - \"Brains\" of the platform. Owned by Databricks in your cloud.\n",
    "    - Orchestrates compute nodes for processing and hosts UI, notebook, code, etc.\n",
    "- **Compute Plane**\n",
    "    - User-controlled. Customer networking, applications, etc.\n",
    "    - For serverless compute, the serverless compute resources run in a serverless compute plane in your Databricks account.\n",
    "    - For classic Databricks compute, the compute resources are in your AWS account in what is called the classic compute plane. This refers to the network in your AWS account and its resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d8a6b",
   "metadata": {},
   "source": [
    "## Building Lakehouses\n",
    "\n",
    "[Delta Lake](https://delta.io/) is an open-source framework that enables building agnostic Lakehouse architecture with compute engines such as Spark, PrestoDB, Snwoflake, Redshift, Databricks, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d081941",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "\n",
    "- **SQL Editor** - Query using SQL on your data\n",
    "- **Databricks Notebook** - Develop models in R and Python\n",
    "- **Databricks Connect** - integrate your favorite IDEs and services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4ed764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "def merge(nums1, m: int, nums2, n: int):\n",
    "        \"\"\"\n",
    "        Do not return anything, modify nums1 in-place instead.\n",
    "        \"\"\"\n",
    "        nums1 = nums1[0:m]\n",
    "        nums2 = nums2[0:n]\n",
    "\n",
    "        nums1 = sorted(nums1+nums2)\n",
    "        return nums1\n",
    "print(merge(nums1 = [1], m = 1, nums2 = [], n = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8363f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Projects-tfkgGnhp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
